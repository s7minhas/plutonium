\section{Reviewer 1}

\subsection{Major Comments}

\begin{enumerate}
    \item From what I follow, the authors are using the dyadic projection of the latent factors in the LFM with respect to China as the dependent variable in the regression model. The LFM is fit to a similarity matrix, in which the outcome variable is the co-voting percentage in UN roll call votes. The problem with this measure is that it ignores attributes of the votes. That is, if two countries vote together on two votes on which all other countries vote the opposite way, it is far more informative about connectivity than if two countries vote together on votes in which the vast majority of other countries vote along with them. Votes will vary systematically on their informativeness regarding states' positioning and similarity to China. This, of course, is a dynamic that is captured and accounted for in established embedding methods for roll call voting (e.g., DW-Nominate, Martin-Quinn scores). One way to define the DV with this data would be to calculate states' positions with roll call votes, and then calculate the linear distance between a state and China. I don't see the need to further filter this data with a method that accounts for network dependence, as the "accounting for" does not occur within the model used to draw inferences in the analysis. Typically, we would use a network model that accounts for dependence AND includes the terms about which we want to draw inference.
    \begin{itemize}
        \item \textcolor{blue}{\emph{
        Insert great response.
        }}
    \end{itemize}
    
    \item Another approach that the authors could consider, which is closer in spirit to network analysis but also would account for features of the votes, is backbone extraction. The authors study a bipartite network (states connected to UN votes) and then collapse that network via the simple percentage co-voting measure. If you read the work on backbone extraction by Zach Neal (Michigan State Psychology) and colleagues, you'll see that simple projection methods such as this discard a lot of valuable information about connectivity. The way backbone projection works is that probabilistic null models are used to define the null distribution of covoting rates, and then the actual co-voting rate is compared to this to create a simulated significance value of the tie between nodes. This simulated significance value of each country with China could be used as the DV.
    \begin{itemize}
        \item \textcolor{blue}{\emph{
        Insert great response.
        }}
    \end{itemize}
    
    \item I do not have a strong reason to expect the conclusions in this study to differ based on using these more established methods. Rather, the methods I recommend are more consistent with how this sort of data is used in the literature, and I don't see the reasoning for using the LFM in the way the authors do it here. I recommend using the current LFM-based measure as a robustness check in the appendix and using one of these recommended methods in the main text.
    \begin{itemize}
        \item \textcolor{blue}{\emph{
        Insert great response.
        }}
    \end{itemize}
    
    \item I have one final comment, and that is that the model of affinity to China seems to have a fairly small number of covariates and is perhaps underspecified. What is the explanatory power in these models? It would improve the identification strategy to include country fixed effects in these models and address concerns about the otherwise fairly small number of variables.
    \begin{itemize}
        \item \textcolor{blue}{\emph{
        Insert great response.
        }}
    \end{itemize}
\end{enumerate}